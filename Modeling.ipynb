{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Leslie/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_2016.csv')\n",
    "prop = pd.read_csv('properties_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prop['bed2bath'] = prop['bedroomcnt']/prop['bathroomcnt']\n",
    "prop['bed2calbath'] = prop['bedroomcnt']/prop['calculatedbathnbr']\n",
    "prop['areaperbedroom'] = prop['calculatedfinishedsquarefeet']/prop['bedroomcnt']\n",
    "prop['livingarearate'] = prop['finishedsquarefeet12']/prop['finishedsquarefeet15']\n",
    "prop['bed2fullbath'] = prop['bedroomcnt']/prop['fullbathcnt']\n",
    "prop['areaperroom'] = prop['calculatedfinishedsquarefeet']/prop['roomcnt']\n",
    "prop['houseage'] = 2016 - prop['yearbuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90811, 62) (90811,)\n"
     ]
    }
   ],
   "source": [
    "for c, dtype in zip(prop.columns, prop.dtypes):\t\n",
    "    if dtype == np.float64:\t\t\n",
    "        prop[c] = prop[c].astype(np.float32)\n",
    "\n",
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "scorer_mae = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "def hyperopt_train_test(params):\n",
    "    t = params['type']\n",
    "    del params['type']\n",
    "    if t == 'xgb':\n",
    "        reg = xgb.XGBRegressor(**params)\n",
    "    else:\n",
    "        return 0, 0\n",
    "    cv_score = cross_val_score(reg, x_train, y_train, scoring=scorer_mae, cv=5)\n",
    "    score_mean = cv_score.mean()\n",
    "    score_std = cv_score.std()\n",
    "    return score_mean, score_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'xgb',\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.02, 0.1),\n",
    "        'min_child_weight': hp.choice('min_child_weight', range(30, 60)),\n",
    "        'max_depth': hp.choice('max_depth', range(5, 10)),\n",
    "        'subsample': hp.uniform('subsample', 0.2, 0.4),\n",
    "        'n_estimators': hp.choice('n_estimators', range(150, 200)),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.4, 0.6),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 1, 2),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 1, 2)\n",
    "}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def f(params):\n",
    "    global best, count\n",
    "    count += 1\n",
    "    result = hyperopt_train_test(params.copy())\n",
    "    acc = result[0]\n",
    "    std = result[1]\n",
    "    print('iters:', count, ', acc:', acc, 'std:', std, '\\nusing', params, '\\n')\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "count = 0 \n",
    "trials = Trials()\n",
    "best = fmin(f, space, algo=tpe.suggest, max_evals=50, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scorer_mae = make_scorer(mean_absolute_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate:0.06, Mean:0.06947398, STD:0.00300854\n",
      "learning_rate:0.061, Mean:0.06948449, STD:0.00301388\n",
      "learning_rate:0.062, Mean:0.06947997, STD:0.00299754\n",
      "learning_rate:0.063, Mean:0.06946019, STD:0.00302769\n",
      "learning_rate:0.064, Mean:0.06943554, STD:0.00301250\n"
     ]
    }
   ],
   "source": [
    "for lr in np.linspace(0.06,0.064,5):\n",
    "    reg = xgb.XGBRegressor(learning_rate=lr, n_estimators=100, max_depth=4, nthread=4, seed=1234)\n",
    "    cv_score = cross_val_score(reg, x_train, y_train, scoring=scorer_mae, cv=3)\n",
    "    score_mean = cv_score.mean()\n",
    "    score_std = cv_score.std()\n",
    "    if score_mean < 0.0696:\n",
    "        print('learning_rate:{0}, Mean:{1:.8f}, STD:{2:.8f}'.format(lr, score_mean, score_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.0001, learning_rate=0.064, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=4,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=1234, silent=True, subsample=1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score: 0.06943554\n",
    "params = {'n_estimators': 100, \n",
    "          'learning_rate': 0.064, \n",
    "          'max_depth': 4,\n",
    "          'nthread': 4,\n",
    "          'gamma': 0.0001,\n",
    "          'seed': 1234}\n",
    "reg = xgb.XGBRegressor()\n",
    "reg.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.0001, learning_rate=0.064, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=4,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=1234, silent=True, subsample=1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Leslie/anaconda3/lib/python3.5/site-packages/IPython/kernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "x_test = df_test[train_columns]\n",
    "\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "# x_test = x_test.values.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_test = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p_test = 0.97*p_test + 0.03*0.011\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test\n",
    "\n",
    "sub.to_csv('result_xgb.csv', index=False, float_format='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "scorer_mae = make_scorer(mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pd.concat([x_train, x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = x.replace(np.inf, 0)\n",
    "\n",
    "for var in x.columns[x_train.dtypes == 'object']:\n",
    "    x[var] = x[var].fillna(x[var].mode())\n",
    "    \n",
    "for var in x.columns[x.dtypes != 'object']:\n",
    "    x[var] = x[var].fillna(x[var].dropna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90811, 62)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x[:90811]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 62)\n",
      "(2985217, 62)\n"
     ]
    }
   ],
   "source": [
    "print(x[90811:].shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_estimators=200  --> 0.07474098\n",
    "for est in [150,200,250,300]:\n",
    "    reg = RandomForestRegressor(n_estimators=est)\n",
    "    cv_score = cross_val_score(reg, x[:90811], y_train, scoring=scorer_mae, cv=3)\n",
    "    score_mean = cv_score.mean()\n",
    "    score_std = cv_score.std()\n",
    "#     if score_mean < 0.0696:\n",
    "    print('n_estimators:{0}, Mean:{1:.8f}, STD:{2:.8f}'.format(est, score_mean, score_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(x_train, y_train, \n",
    "                                                  test_size=0.3,\n",
    "                                                  random_state=1234)\n",
    "\n",
    "d_train = lgb.Dataset(xtrain, label=ytrain)\n",
    "d_valid = lgb.Dataset(xvalid, label=yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['max_bin'] = 40\n",
    "params['learning_rate'] = 0.0005  # 0.06890525\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'l1'          # or 'mae'\n",
    "params['feature_fraction'] = 0.8\n",
    "params['sub_feature'] = 0.6      # feature_fraction \n",
    "params['bagging_freq'] = 50\n",
    "params['num_leaves'] = 100       # num_leaf\n",
    "params['min_data'] = 400         # min_data_in_leaf\n",
    "params['min_hessian'] = 0.05 \n",
    "\n",
    "# Score:0.06881544\n",
    "# learning_rate: 0.0005\n",
    "# feature_fraction: 0.8\n",
    "# sub_feature:0.6\n",
    "# bagging_freq:50\n",
    "# num_leaves:100\n",
    "# min_data:400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:0.06884878, min_data:100\n",
      "Score:0.06883632, min_data:200\n",
      "Score:0.06882509, min_data:300\n",
      "Score:0.06881544, min_data:400\n"
     ]
    }
   ],
   "source": [
    "best = 0.06890525\n",
    "watchlist = [d_valid]\n",
    "for mh in [100,200,300,400]:\n",
    "    params['min_hessian'] = md\n",
    "    clf = lgb.train(params, d_train, 500, watchlist, verbose_eval=False)\n",
    "    yvalid_pred = clf.predict(x_valid)\n",
    "    mae = mean_absolute_error(y_pred=yvalid_pred, y_true=y_valid)\n",
    "    if mae < best:\n",
    "        print('Score:{0:.8f}, min_hessian:{1}'.format(mae, md))\n",
    "#               print('Score:{0:.8f}, learning rate:{1}, max_bin:{2}, feature_fraction:{3}, bagging_freq:{4}, num_leaves:{5}'.format(mae, lr, m_bin, feat_frac, bag_freq, leaves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "watchlist = [d_valid]\n",
    "clf = lgb.train(params, d_train, 500, watchlist, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Leslie/anaconda3/lib/python3.5/site-packages/IPython/kernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "x_test = df_test[train_columns]\n",
    "\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.reset_parameter({\"num_threads\":2})\n",
    "p_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011075240581464639"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_test = 0.9*p_test + 0.1*0.011\n",
    "\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test\n",
    "\n",
    "sub.to_csv('result.csv', index=False, float_format='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_valid_pred = clf.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_art = 0.95*y_valid_pred + 0.05*0.0118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0718193790386\n"
     ]
    }
   ],
   "source": [
    "# 0.0718179\n",
    "print('Score:', mean_absolute_error(y_pred=y_art, y_true=y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv('results/result_0.0646523.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = result['201610']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ParcelId', '201610', '201611', '201612', '201710', '201711', '201712'], dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['201611'] = y_pred*(1+0.022369)\n",
    "result['201612'] = y_pred*(1+0.022369)**2\n",
    "result['201710'] = y_pred*(1+0.022369)**6\n",
    "result['201711'] = y_pred*(1+0.022369)**7\n",
    "result['201712'] = y_pred*(1+0.022369)**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.to_csv('result_timeseries.csv', index=False, float_format='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3(Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
