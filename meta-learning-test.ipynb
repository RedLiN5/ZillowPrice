{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import collections\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         var1  \\\n",
      "num_category                                                6   \n",
      "counter       {1: 349, 2: 97, 3: 165, 4: 221, 5: 247, 6: 122}   \n",
      "\n",
      "                                                       var2             var3  \n",
      "num_category                                              6                2  \n",
      "counter       {2049: 1, 2: 13, 3: 32, 4: 47, 5: 115, 6: 50}  {1: 245, 4: 25}  \n"
     ]
    }
   ],
   "source": [
    "data_base = np.array([[6,{1: 349, 2: 97, 3: 165, 4: 221, 5: 247, 6: 122}],\n",
    "                      [6,{2049: 1, 2: 13, 3: 32, 4: 47, 5: 115, 6: 50}],\n",
    "                      [2,{1:245, 4:25}]]).T\n",
    "features_base = pd.DataFrame(columns=['var1', 'var2', 'var3'],index=['num_category', 'counter'], data=data_base)\n",
    "print(features_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         var1  \\\n",
      "num_category                                                6   \n",
      "counter       {1: 321, 2: 58, 3: 147, 4: 210, 5: 263, 6: 150}   \n",
      "\n",
      "                                 var2  \n",
      "num_category                        3  \n",
      "counter       {1: 210, 4: 39, 6: 100}  \n"
     ]
    }
   ],
   "source": [
    "data_input= np.array([[6,{1: 321, 2: 58, 3: 147, 4: 210, 5: 263, 6: 150}],\n",
    "                      [3,{1: 210, 4: 39, 6: 100}]]).T\n",
    "features_input = pd.DataFrame(columns=['var1', 'var2'],\n",
    "                              index=['num_category', 'counter'], \n",
    "                              data=data_input)\n",
    "print(features_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_colnames = features_input.columns\n",
    "base_colnames = features_base.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_table = pd.DataFrame(columns=base_colnames,index=input_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1 var2 var3\n",
       "var1  NaN  NaN  NaN\n",
       "var2  NaN  NaN  NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_input = 'var1'\n",
    "var_base  = 'var2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter_input = features_input.ix['counter', var_input]\n",
    "counter_base  = features_base.ix['counter', var_base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys_input = counter_input.keys()\n",
    "keys_base = counter_base.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersect = set(keys_base).intersection(set(keys_input))\n",
    "sample_input = []\n",
    "sample_base = []\n",
    "for key in intersect:\n",
    "    sample_input.append(counter_input[key])\n",
    "    sample_base.append(counter_base[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(sample_input, sample_base)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_table = pd.DataFrame(columns=base_colnames,\n",
    "                           index=input_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var_input in input_colnames:\n",
    "    for var_base in base_colnames:\n",
    "        counter_input = features_input.ix['counter', var_input]\n",
    "        counter_base  = features_base.ix['counter', var_base]\n",
    "        keys_input = counter_input.keys()\n",
    "        keys_base = counter_base.keys()\n",
    "        intersect = set(keys_base).intersection(set(keys_input))\n",
    "        sample_input = []\n",
    "        sample_base = []\n",
    "        for key in intersect:\n",
    "            sample_input.append(counter_input[key])\n",
    "            sample_base.append(counter_base[key])\n",
    "        pvalue = stats.chisquare(sample_input, sample_base)[1]\n",
    "        score_table.ix[var_input, var_base] = pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var1</th>\n",
       "      <td>3.80632e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6256e-305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var2</th>\n",
       "      <td>3.7196e-46</td>\n",
       "      <td>7.68227e-13</td>\n",
       "      <td>0.000339288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             var1         var2         var3\n",
       "var1  3.80632e-05            0  8.6256e-305\n",
       "var2   3.7196e-46  7.68227e-13  0.000339288"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-50-359ad8e53af8>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-359ad8e53af8>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    i = 1\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def _select_candicate_short(score_df):\n",
    "    candidates = []\n",
    "    candidate_scores = []\n",
    "    input_colnames = score_df.index\n",
    "    for i in range(len(input_colnames)):\n",
    "        row = score_table.ix[i,:]\n",
    "        j = 1\n",
    "        for _ in range(len(series_row)):\n",
    "            value = series_row.nlargest(i)[-1]\n",
    "            name = series_row.index[series_row==value][0]\n",
    "            if name in candidates_list:\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "        candidates.append(name)\n",
    "        candidate_scores.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate_scores_numeric = [1,6,3,3,6,4,6]\n",
    "candidate_scores_category = [6,3,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 3, 3, 6, 4, 6, 6, 3, 8]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_scores_numeric +candidate_scores_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[1.000000,  0.540177,  0.468184,  0.321686,  0.924689],\n",
    "                 [0.540177,  1.000000,  0.312699,  0.373298,  0.491943],\n",
    "                 [0.468184,  0.312699,  1.000000,  0.297596,  0.438892]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_score_table = pd.DataFrame(columns=['var1', 'var2', 'var3', 'var4', 'var5'], index=['var1','var2','var3'], data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>var1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540177</td>\n",
       "      <td>0.468184</td>\n",
       "      <td>0.321686</td>\n",
       "      <td>0.924689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var2</th>\n",
       "      <td>0.540177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312699</td>\n",
       "      <td>0.373298</td>\n",
       "      <td>0.491943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var3</th>\n",
       "      <td>0.468184</td>\n",
       "      <td>0.312699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297596</td>\n",
       "      <td>0.438892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          var1      var2      var3      var4      var5\n",
       "var1  1.000000  0.540177  0.468184  0.321686  0.924689\n",
       "var2  0.540177  1.000000  0.312699  0.373298  0.491943\n",
       "var3  0.468184  0.312699  1.000000  0.297596  0.438892"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_score_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _select_candicate_short(score_df):\n",
    "    candidates = []\n",
    "    candidate_scores = []\n",
    "    input_colnames = score_df.index\n",
    "    for i in range(len(input_colnames)):\n",
    "        row = score_df.ix[i,:]\n",
    "        j = 1\n",
    "        for _ in range(len(row)):\n",
    "            value = row.nlargest(j)[-1]\n",
    "            name = row.index[row==value][0]\n",
    "            if name in candidates:\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "        candidates.append(name)\n",
    "        candidate_scores.append(value)\n",
    "    return candidates, candidate_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var1', 'var2', 'var3'] [1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "candidates, scores = _select_candicate_short(_score_table)\n",
    "print(candidates, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_colnames = _score_table.index\n",
    "for i in range(len(input_colnames)):\n",
    "    row = _score_table.ix[i,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46818399999999999"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.nlargest(2)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble.forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and use averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is always the same as the original\n",
      " |  input sample size but the samples are drawn with replacement if\n",
      " |  `bootstrap=True` (default).\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : integer, optional (default=10)\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |  criterion : string, optional (default=\"gini\")\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=\"auto\")\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a percentage and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_depth : integer or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a percentage and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a percentage and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for percentages.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_split : float, optional (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  bootstrap : boolean, optional (default=True)\n",
      " |      Whether bootstrap samples are used when building trees.\n",
      " |  \n",
      " |  oob_score : bool (default=False)\n",
      " |      Whether to use out-of-bag samples to estimate\n",
      " |      the generalization accuracy.\n",
      " |  \n",
      " |  n_jobs : integer, optional (default=1)\n",
      " |      The number of jobs to run in parallel for both `fit` and `predict`.\n",
      " |      If -1, then the number of jobs is set to the number of cores.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  verbose : int, optional (default=0)\n",
      " |      Controls the verbosity of the tree building process.\n",
      " |  \n",
      " |  warm_start : bool, optional (default=False)\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest.\n",
      " |  \n",
      " |  class_weight : dict, list of dicts, \"balanced\",\n",
      " |      \"balanced_subsample\" or None, optional (default=None)\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : array of shape = [n_classes] or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances (the higher, the more important the feature).\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |  \n",
      " |  oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier, ExtraTreesClassifier\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      abc.NewBase\n",
      " |      BaseForest\n",
      " |      abc.NewBase\n",
      " |      sklearn.ensemble.base.BaseEnsemble\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.feature_selection.from_model._LearntSelectorMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest. The\n",
      " |      class probability of a single tree is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n",
      " |          such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples, n_estimators]\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |      \n",
      " |      n_nodes_ptr : array of size (n_estimators + 1, )\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances (the higher, the more important the\n",
      " |         feature).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble.base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Returns iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection.from_model._LearntSelectorMixin:\n",
      " |  \n",
      " |  transform(*args, **kwargs)\n",
      " |      DEPRECATED: Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      " |      \n",
      " |      Reduce X to its most important features.\n",
      " |      \n",
      " |              Uses ``coef_`` or ``feature_importances_`` to determine the most\n",
      " |              important features.  For models with a ``coef_`` for each class, the\n",
      " |              absolute sum over the classes is used.\n",
      " |      \n",
      " |              Parameters\n",
      " |              ----------\n",
      " |              X : array or scipy sparse matrix of shape [n_samples, n_features]\n",
      " |                  The input samples.\n",
      " |      \n",
      " |              threshold : string, float or None, optional (default=None)\n",
      " |                  The threshold value to use for feature selection. Features whose\n",
      " |                  importance is greater or equal are kept while the others are\n",
      " |                  discarded. If \"median\" (resp. \"mean\"), then the threshold value is\n",
      " |                  the median (resp. the mean) of the feature importances. A scaling\n",
      " |                  factor (e.g., \"1.25*mean\") may also be used. If None and if\n",
      " |                  available, the object attribute ``threshold`` is used. Otherwise,\n",
      " |                  \"mean\" is used by default.\n",
      " |      \n",
      " |              Returns\n",
      " |              -------\n",
      " |              X_r : array of shape [n_samples, n_selected_features]\n",
      " |                  The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithm = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 7,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_split': 1e-07,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestClassifier'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.fit(np.array([[1],[2],[3],[4]]), np.array([1,1,0,0]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 7,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_split': 1e-07,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = algorithm.get_params()\n",
    "algorithm_name = algorithm.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algorithm_params = {algorithm_name: hyperparameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spambase_test1': {'RandomForestClassifier': {'min_impurity_split': 1e-07, 'verbose': 0, 'n_jobs': 1, 'criterion': 'gini', 'max_features': 'auto', 'bootstrap': True, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'min_samples_leaf': 1, 'max_leaf_nodes': None, 'random_state': None, 'oob_score': False, 'class_weight': None, 'max_depth': 7, 'warm_start': False, 'n_estimators': 500}}}\n"
     ]
    }
   ],
   "source": [
    "itemdict = {}\n",
    "itemdict['spambase_test1'] = algorithm_params\n",
    "print(itemdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('/Users/Leslie/GitHub/meta-learning/config/hyperparameter', 'wb') as fp:\n",
    "        pickle.dump(itemdict, fp)\n",
    "except Exception as e:\n",
    "    print(e, 'in writing hyperparameter')\n",
    "    itemdict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "try:\n",
    "    with open('/Users/Leslie/GitHub/meta-learning/config/metabase', 'rb') as fp:\n",
    "        itemdict = pickle.load(fp)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_category</th>\n",
       "      <td>271</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counter</th>\n",
       "      <td>{1: 349, 2: 97, 3: 165, 4: 221, 5: 247, 6: 122...</td>\n",
       "      <td>{2049: 1, 2: 13, 3: 32, 4: 47, 5: 115, 6: 50, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           var1  \\\n",
       "num_category                                                271   \n",
       "counter       {1: 349, 2: 97, 3: 165, 4: 221, 5: 247, 6: 122...   \n",
       "\n",
       "                                                           var2  \n",
       "num_category                                                919  \n",
       "counter       {2049: 1, 2: 13, 3: 32, 4: 47, 5: 115, 6: 50, ...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemdict['spambase_test1']['Info_Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>var10</th>\n",
       "      <th>...</th>\n",
       "      <th>var46</th>\n",
       "      <th>var47</th>\n",
       "      <th>var48</th>\n",
       "      <th>var49</th>\n",
       "      <th>var50</th>\n",
       "      <th>var51</th>\n",
       "      <th>var52</th>\n",
       "      <th>var53</th>\n",
       "      <th>var54</th>\n",
       "      <th>var55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kurtosis</th>\n",
       "      <td>49.250196</td>\n",
       "      <td>105.531394</td>\n",
       "      <td>13.292981</td>\n",
       "      <td>725.661025</td>\n",
       "      <td>37.898646</td>\n",
       "      <td>68.369596</td>\n",
       "      <td>75.330206</td>\n",
       "      <td>168.977796</td>\n",
       "      <td>46.887956</td>\n",
       "      <td>161.038195</td>\n",
       "      <td>...</td>\n",
       "      <td>150.734577</td>\n",
       "      <td>458.933036</td>\n",
       "      <td>536.907777</td>\n",
       "      <td>212.835415</td>\n",
       "      <td>392.986452</td>\n",
       "      <td>617.802400</td>\n",
       "      <td>606.794448</td>\n",
       "      <td>199.735160</td>\n",
       "      <td>1217.168584</td>\n",
       "      <td>669.639120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>5.673789</td>\n",
       "      <td>10.083522</td>\n",
       "      <td>3.008267</td>\n",
       "      <td>26.219193</td>\n",
       "      <td>4.745578</td>\n",
       "      <td>5.955010</td>\n",
       "      <td>6.763375</td>\n",
       "      <td>9.721677</td>\n",
       "      <td>5.224363</td>\n",
       "      <td>8.485042</td>\n",
       "      <td>...</td>\n",
       "      <td>10.119362</td>\n",
       "      <td>19.861214</td>\n",
       "      <td>19.714016</td>\n",
       "      <td>13.704152</td>\n",
       "      <td>13.579326</td>\n",
       "      <td>21.076671</td>\n",
       "      <td>18.651921</td>\n",
       "      <td>11.159501</td>\n",
       "      <td>31.051937</td>\n",
       "      <td>23.754176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179824</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305324</td>\n",
       "      <td>1.290435</td>\n",
       "      <td>0.504088</td>\n",
       "      <td>1.395000</td>\n",
       "      <td>0.672440</td>\n",
       "      <td>0.273794</td>\n",
       "      <td>0.391399</td>\n",
       "      <td>0.401028</td>\n",
       "      <td>0.278586</td>\n",
       "      <td>0.644685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911020</td>\n",
       "      <td>0.076266</td>\n",
       "      <td>0.285704</td>\n",
       "      <td>0.243445</td>\n",
       "      <td>0.270326</td>\n",
       "      <td>0.109382</td>\n",
       "      <td>0.815583</td>\n",
       "      <td>0.245855</td>\n",
       "      <td>0.429295</td>\n",
       "      <td>31.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.050000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_quartile</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_quartile</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows  55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     var1        var2       var3        var4       var5  \\\n",
       "kurtosis        49.250196  105.531394  13.292981  725.661025  37.898646   \n",
       "skewness         5.673789   10.083522   3.008267   26.219193   4.745578   \n",
       "mean             0.104553    0.213015   0.280656    0.065425   0.312223   \n",
       "std              0.305324    1.290435   0.504088    1.395000   0.672440   \n",
       "min              0.000000    0.000000   0.000000    0.000000   0.000000   \n",
       "max              4.540000   14.280000   5.100000   42.810000  10.000000   \n",
       "median           0.000000    0.000000   0.000000    0.000000   0.000000   \n",
       "first_quartile   0.000000    0.000000   0.000000    0.000000   0.000000   \n",
       "third_quartile   0.000000    0.000000   0.420000    0.000000   0.380000   \n",
       "\n",
       "                     var6       var7        var8       var9       var10  \\\n",
       "kurtosis        68.369596  75.330206  168.977796  46.887956  161.038195   \n",
       "skewness         5.955010   6.763375    9.721677   5.224363    8.485042   \n",
       "mean             0.095901   0.114208    0.105295   0.090067    0.239413   \n",
       "std              0.273794   0.391399    0.401028   0.278586    0.644685   \n",
       "min              0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "max              5.880000   7.270000   11.110000   5.260000   18.180000   \n",
       "median           0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "first_quartile   0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "third_quartile   0.000000   0.000000    0.000000   0.000000    0.160000   \n",
       "\n",
       "                   ...            var46       var47       var48       var49  \\\n",
       "kurtosis           ...       150.734577  458.933036  536.907777  212.835415   \n",
       "skewness           ...        10.119362   19.861214   19.714016   13.704152   \n",
       "mean               ...         0.179824    0.005444    0.031869    0.038575   \n",
       "std                ...         0.911020    0.076266    0.285704    0.243445   \n",
       "min                ...         0.000000    0.000000    0.000000    0.000000   \n",
       "max                ...        22.050000    2.170000   10.000000    4.385000   \n",
       "median             ...         0.000000    0.000000    0.000000    0.000000   \n",
       "first_quartile     ...         0.000000    0.000000    0.000000    0.000000   \n",
       "third_quartile     ...         0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "                     var50       var51       var52       var53        var54  \\\n",
       "kurtosis        392.986452  617.802400  606.794448  199.735160  1217.168584   \n",
       "skewness         13.579326   21.076671   18.651921   11.159501    31.051937   \n",
       "mean              0.139030    0.016976    0.269071    0.075811     0.044238   \n",
       "std               0.270326    0.109382    0.815583    0.245855     0.429295   \n",
       "min               0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "max               9.752000    4.081000   32.478000    6.003000    19.829000   \n",
       "median            0.065000    0.000000    0.000000    0.000000     0.000000   \n",
       "first_quartile    0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "third_quartile    0.188000    0.000000    0.315000    0.052000     0.000000   \n",
       "\n",
       "                      var55  \n",
       "kurtosis         669.639120  \n",
       "skewness          23.754176  \n",
       "mean               5.191515  \n",
       "std               31.726000  \n",
       "min                1.000000  \n",
       "max             1102.500000  \n",
       "median             2.276000  \n",
       "first_quartile     1.588000  \n",
       "third_quartile     3.706000  \n",
       "\n",
       "[9 rows x 55 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemdict['spambase_test1']['Info_Numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/Leslie/GitHub/meta-learning/config/hyperparameter', 'rb') as fp:\n",
    "    itemdict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spambase_test1': {'RandomForestClassifier': {'bootstrap': True,\n",
       "   'class_weight': None,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'max_features': 'auto',\n",
       "   'max_leaf_nodes': None,\n",
       "   'min_impurity_split': 1e-07,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'min_weight_fraction_leaf': 0.0,\n",
       "   'n_estimators': 500,\n",
       "   'n_jobs': 1,\n",
       "   'oob_score': False,\n",
       "   'random_state': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False}}}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "reg = xgb.XGBClassifier()\n",
    "algorithm_name = reg.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {'colsample_bytree': 0.67660778015155687,\n",
    " 'learning_rate': 0.027660778015155693,\n",
    " 'max_depth': 6,\n",
    " 'min_child_weight': 45,\n",
    " 'n_estimators': 197,\n",
    " 'reg_alpha': 1.3830389007577846,\n",
    " 'reg_lambda': 1.3830389007577846,\n",
    " 'subsample': 0.43830389007577847}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algorithm_params = {algorithm_name: hyperparameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemdict['credit_approval'] = algorithm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/Leslie/GitHub/meta-learning/config/hyperparameter', 'wb') as fp:\n",
    "    pickle.dump(itemdict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(hyperparameters, dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/Users/Leslie/GitHub/meta-learning/config/metabase', 'rb') as fp:\n",
    "    itemdict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spambase_test1': {'Business_Function': 'IT',\n",
       "  'Industry': 'Internet',\n",
       "  'Info_Category':                                                            var1  \\\n",
       "  num_category                                                271   \n",
       "  counter       {1: 349, 2: 97, 3: 165, 4: 221, 5: 247, 6: 122...   \n",
       "  \n",
       "                                                             var2  \n",
       "  num_category                                                919  \n",
       "  counter       {2049: 1, 2: 13, 3: 32, 4: 47, 5: 115, 6: 50, ...  ,\n",
       "  'Info_Numeric':                      var1        var2       var3        var4       var5  \\\n",
       "  kurtosis        49.250196  105.531394  13.292981  725.661025  37.898646   \n",
       "  skewness         5.673789   10.083522   3.008267   26.219193   4.745578   \n",
       "  mean             0.104553    0.213015   0.280656    0.065425   0.312223   \n",
       "  std              0.305324    1.290435   0.504088    1.395000   0.672440   \n",
       "  min              0.000000    0.000000   0.000000    0.000000   0.000000   \n",
       "  max              4.540000   14.280000   5.100000   42.810000  10.000000   \n",
       "  median           0.000000    0.000000   0.000000    0.000000   0.000000   \n",
       "  first_quartile   0.000000    0.000000   0.000000    0.000000   0.000000   \n",
       "  third_quartile   0.000000    0.000000   0.420000    0.000000   0.380000   \n",
       "  \n",
       "                       var6       var7        var8       var9       var10  \\\n",
       "  kurtosis        68.369596  75.330206  168.977796  46.887956  161.038195   \n",
       "  skewness         5.955010   6.763375    9.721677   5.224363    8.485042   \n",
       "  mean             0.095901   0.114208    0.105295   0.090067    0.239413   \n",
       "  std              0.273794   0.391399    0.401028   0.278586    0.644685   \n",
       "  min              0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "  max              5.880000   7.270000   11.110000   5.260000   18.180000   \n",
       "  median           0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "  first_quartile   0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "  third_quartile   0.000000   0.000000    0.000000   0.000000    0.160000   \n",
       "  \n",
       "                     ...            var46       var47       var48       var49  \\\n",
       "  kurtosis           ...       150.734577  458.933036  536.907777  212.835415   \n",
       "  skewness           ...        10.119362   19.861214   19.714016   13.704152   \n",
       "  mean               ...         0.179824    0.005444    0.031869    0.038575   \n",
       "  std                ...         0.911020    0.076266    0.285704    0.243445   \n",
       "  min                ...         0.000000    0.000000    0.000000    0.000000   \n",
       "  max                ...        22.050000    2.170000   10.000000    4.385000   \n",
       "  median             ...         0.000000    0.000000    0.000000    0.000000   \n",
       "  first_quartile     ...         0.000000    0.000000    0.000000    0.000000   \n",
       "  third_quartile     ...         0.000000    0.000000    0.000000    0.000000   \n",
       "  \n",
       "                       var50       var51       var52       var53        var54  \\\n",
       "  kurtosis        392.986452  617.802400  606.794448  199.735160  1217.168584   \n",
       "  skewness         13.579326   21.076671   18.651921   11.159501    31.051937   \n",
       "  mean              0.139030    0.016976    0.269071    0.075811     0.044238   \n",
       "  std               0.270326    0.109382    0.815583    0.245855     0.429295   \n",
       "  min               0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "  max               9.752000    4.081000   32.478000    6.003000    19.829000   \n",
       "  median            0.065000    0.000000    0.000000    0.000000     0.000000   \n",
       "  first_quartile    0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "  third_quartile    0.188000    0.000000    0.315000    0.052000     0.000000   \n",
       "  \n",
       "                        var55  \n",
       "  kurtosis         669.639120  \n",
       "  skewness          23.754176  \n",
       "  mean               5.191515  \n",
       "  std               31.726000  \n",
       "  min                1.000000  \n",
       "  max             1102.500000  \n",
       "  median             2.276000  \n",
       "  first_quartile     1.588000  \n",
       "  third_quartile     3.706000  \n",
       "  \n",
       "  [9 rows x 55 columns]}}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3(Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
